###################
####Functions######
###################
# library(tidyverse)
inx <- function (tours, inp.n) { # data: current dataframe; inp.n: position for non-inputs
  # numeric input indicator
  indx <- sapply(tours, is.numeric)
  indx[inp.n]<-FALSE
  
  # nominal input indicator
  index.cat<-sapply(tours, is.factor)
  index.cat[inp.n]<-FALSE
  
  # missing value indicator
  index.na<-sapply(tours,function(x) any(is.na(x)))
  index.na[inp.n]<-FALSE
  
  data.frame(indx, index.cat, index.na)
}

impute <- function(x,y) {
  x[is.na(x)]<-y
  x
}

## Mode function ##
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
## Mean function ##
means <- function(x) { mean(x, na.rm = TRUE) }

####################
##  load "dat_con.Rdata"
tours <- dat_con

tours$Recommend_GAT<-as.factor(tours$Recommend_GAT)
tours$TravelAgain<-as.factor(tours$TravelAgain)
tours$Groups_Interest<-as.factor(tours$Groups_Interest)
tours$Reference<-as.factor(tours$Reference)

tours$Overall_Impression<-factor(tours$Overall_Impression,ordered = T)
tours$Pre_Departure<-factor(tours$Pre_Departure,ordered = T)
tours$Flight_Itin<-factor(tours$Flight_Itin,ordered=T)
tours$TD_Overall<-factor(tours$TD_Overall,ordered = T)

tours$Extension<-as.factor(tours$Extension)
tours$Insurance<-as.factor(tours$Insurance)
tours$FltGty<-as.factor(tours$FltGty)
tours$Complaint_Event<-as.factor(tours$Complaint_Event)
tours$Voucher_Event<-as.factor(tours$Voucher_Event)


tours$Outbound_Connections <- as.factor(tours$Outbound_Connections)
tours$Return_Connections <- as.factor(tours$Return_Connections)

##########################
### Fix "Date" levels ###
##########################
tours$TourDate <- as.Date(tours$TourDate, "%m/%d/%Y")
tours$TourDate <- format(tours$TourDate, "%m/%Y")
tours$TourDate <- as.factor(tours$TourDate)

##########################
###  Fix "Time" levels ###
##########################
# library(chron)
ind <- c(76,82,85,91)
colnames(tours)[ind]  # check the names

## convert to time 
for (i in seq(1:4)){
  temp <- ind[i]
  tours[,temp] <- times(tours[,temp])
}

## only keep hour
for (i in seq(1:4)){
  temp <- ind[i]
  tours[,temp] <- hours(tours[,temp])
}

## convert to factor var
for (i in seq(1:4)){
  temp <- ind[i]
  tours[ ,temp] <- as.factor(tours[ ,temp])
}

tours$Grp_Size_ratio_Con <- as.factor(tours$Grp_Size_ratio_Con)
tours$Age_Con <- as.factor(tours$Age_Con)
tours$State_Con <- as.factor(tours$State_Con)

#-1 is missing here so assign na
tours$Outbound_Connections[tours$Outbound_Connections %in% c(-3,-2,-1,4,5)]<-NA
tours$Return_Connections[tours$Return_Connections %in% c(-3,-2,-1,4,5)]<-NA

sort(sapply(tours, function(x) sum(is.na(x))),decreasing = T)

# library(rpart)
# library(caret)
# library(caTools)
set.seed(27947)
split = sample.split(tours$Book_12Mo, SplitRatio = 0.5)
split.valid<-!split
split.test<-!split
split2<-sample.split(tours$Book_12Mo[!split],SplitRatio = 1/2)
split.valid[split.valid==TRUE]= split2
split.test[split.test==TRUE]= !split2


######################
##tree consolidation##
#####################
# library(tree.bins)


consldt<-tours[split,] %>% 
  select(TourCode,Outbound_Domestic_Gateway,Return_Domestic_Gateway,
         Book_12Mo)

binned <- tree.bins(data = consldt, y = Book_12Mo,
                    bin.nm = "Group.", control = rpart.control(cp = .001),
                    return = "new.factors")

#Add consolidated categories for training data to new.tours df
tours["TourCode_Groups"] <- as.factor(binned[[1]]$Categories[match(tours$TourCode,binned[[1]]$TourCode)])
tours["Outbound_Domestic_Gateway_Groups"] <- as.factor(binned[[2]]$Categories[match(tours$Outbound_Domestic_Gateway,binned[[2]]$Outbound_Domestic_Gateway)])
tours["Return_Domestic_Gateway_Groups"] <- as.factor(binned[[3]]$Categories[match(tours$Return_Domestic_Gateway,binned[[3]]$Return_Domestic_Gateway)])

### Create a name list  ###
var_names <- as.data.frame(seq(from=1, to=ncol(tours)), col.names="index")
colnames(var_names)[1] <-"index"
var_names$names <- names(tours)

###  the following variables will be removed  ###
rem <- c(2:7, 10:12, 14:16, 18, 58, 63, 67, 72, 73:75,77,79,81, 84,86,88,90,95)
var_names$names[rem]
## 1] "Cus_ID"                    "FY"                        "ProdTour_ID"               "SalesTourID"              
## [5] "Trip_no"                   "Tour_Season"               "Tour_Days"                 "Start_Day"                
## [9] "End_Day"                   "Grp_Size_Cat"              "Grp_Size"                  "Capacity"                 
## [13] "TourCode"                  "HH_ID"                     "State"                     "Promo_Disc"               
## [17] "Complaint_Event"           "Eval_Contact_Days"         "Voucher_Event"             "Outbound_Domestic_Gateway"
## [21] "Outbound_Connect_Gateway1" "Outbound_Connect_Gateway2" "Outbound_Intr_Gateway"     "Return_Intr_Gateway"      
## [25] "Return_Connect_Gateway1"   "Return_Connect_Gateway2"  "Return_Domestic_Gateway"  

tours$Book_12Mo <- as.factor(tours$Book_12Mo)
tours$Tour_Days_Con <- as.factor(tours$Tour_Days_Con)
new.tours<-tours[,-rem]



######################
##### Imputation #####
######################
tours.imp <- new.tours
#Routine Update#
inp.n <- grep("^(EvalID|Book_12Mo)$",names(tours.imp))
inx3<-inx(tours.imp, inp.n) 
indx<-inx3$indx
index.cat<-inx3$index.cat
index.na<-inx3$index.na
#####################

names(tours.imp)[index.na==T]
summary(tours.imp[index.na])


# numeric impute: By mean #
Mean<-sapply(tours.imp[split,indx],means)##remove in scoring already saved!!
tours.imp[indx]<-as.data.frame(mapply(impute,x=tours.imp[indx],y = Mean))

# Nominal Input: By Mode #
Mode<-sapply(tours.imp[split, index.cat],mode)
tours.imp[index.cat]<-as.data.frame(mapply(impute,x=tours.imp[index.cat],y = Mode))

sort(sapply(tours.imp, function(x) sum(is.na(x))),decreasing = T)

# library(Amelia)
# missmap(tours.imp)
# dev.off()


# create missing value flag #
tours.imp[paste(names(tours.imp)[index.na], "NA", sep=".")] <- ifelse(
  is.na(tours.imp[index.na]), 1, 0)

tours.imp[grep("NA$",names(tours.imp))]<-lapply(
  tours.imp[grep("NA$",names(tours.imp))], as.factor) 

#######################
#### Random Forest #### internal downsampling
#######################

tours.rf<-tours.imp
str(tours.rf)
vars1 <- -grep("^(EvalID|State)$",names(tours.rf))


minor<-unname(summary(tours.rf$Book_12Mo[split])[2])


# library(randomForest)
set.seed(27947)

m.best<-12

################################
#### Parameter Tuning: mtry ####
################################

m<-round(seq(5,30,by=8))
m<-seq(6,20,by=3)
fscore.seq<-numeric()

for(i in 1:length(m)){
  set.seed(27947)
  rf <- randomForest(Book_12Mo~., data=tours.rf[split,vars1],
                     ntree = 200,
                     strata= tours.rf$Book_12Mo[split],
                     sampsize=c(minor,minor),
                     importance =TRUE,
                     mtry=m[i])
  rf.class<- predict(rf, newdata=tours.rf[split.valid,], type="response")
  fscore.seq[i]<-confusionMatrix(table(rf.class,tours.rf$Book_12Mo[split.valid]),
                                 positive = "1")$byClass["F1"]
  cat(i,"/",length(m),": Finished making forest #",i," with mtry =",m[i],"and F1 =",round(fscore.seq[i],3))
  cat("\n")
}


m.best=9

#######################
#### Random Forest ####
#######################
set.seed(27947)
RF <- randomForest(Book_12Mo~., data=tours.rf[split,vars1],
                   ntree = 200, 
                   strata= tours.rf$Book_12Mo[split], 
                   sampsize=c(minor,minor),
                   importance =TRUE,mtry=m.best,#from below
                   do.trace=TRUE)
print(RF)
plot(RF)  



# Make predictions #
library(caret)
RF.class<- predict(RF, newdata=tours.rf[split.test,], type="response")
confusionMatrix(table(RF.class,tours.rf[split.test,]$Book_12Mo),positive = "1")
fscore<-confusionMatrix(table(RF.class,tours.rf[split.test,]$Book_12Mo),
                        positive = "1")$byClass["F1"]  
fscore #0.55679

RF$importance
varImpPlot(RF) 


confusionMatrix(table(RF.class,tours.rf[split.test,]$Book_12Mo),positive = "1")

###################
## Well, the F-score is about 0.547, but I improved the sensitivity to 0.723, which was about 0.6
## the problem for this model is predict too many 1. I feel I need delete some inputs

###################
## Well, the F-score is about 0.547, but I improved the sensitivity to 0.723, which was about 0.6
## the problem for this model is predict too many 1. I feel I need delete some inputs


########################################
######### Logistic Regression ##########
########################################

## If you run really full model, I don't know how long will it take.
## So I just select the top variables selected by RF
tours.mdl<-tours.imp[c("Book_12Mo","TourDate","Email","Tour_Region","Domestic_Depart_Time","Intr_Depart_Time",
                       "Intr_Arrival_Time","Domestic_Arrival_Time","Past_Trips","TourCode_Groups",
                       "Return_Connect_Time_Mins_1","Age_Con", "DB_Enter_Months","Return_Domestic_Gateway_Groups",
                       "TourPriceCat","Pax_Category","SourceType","Tour_Type","State_Con","Grp_Size_ratio_Con")]
# vars <- grep("^(EvalID|State|.NA$)",names(tours.mdl))

levels(tours.mdl$Book_12Mo)


vars <- -c(1, 74:84)

full <- glm(Book_12Mo ~. , family=binomial, data=tours.mdl[split,])
null<-glm(Book_12Mo ~1, family=binomial, data=tours.mdl[split, ])


n<-sum(split)

#Stepwise
reg.bwd <- step(full, direction="back",k=log(n))
reg.fwd <- step(null,scope=formula(full), direction="forward",k=log(n))

summary(reg.bwd)

# library(pROC)
reg.bwd.prob<-predict(reg.bwd,tours.mdl[split.valid, ], type = "response") 
rocCurve.reg <- roc(tours.mdl[split.valid,]$Book_12Mo, reg.bwd.prob)
regThresh <-  coords(rocCurve.reg, x = "best", best.method = "closest.topleft", transpose = FALSE)

reg.class <- as.factor(ifelse(reg.bwd.prob >= regThresh$threshold, 1,0))
reg.fscore<-confusionMatrix(table(reg.class,new.tours[split.valid,]$Book_12Mo),
                            positive = "1")$byClass["F1"]




########################################
####### Artificial Neural Network ######
########################################


#####################
## ANN Preparation ##
#####################

tours.ann<-tours.mdl


ScaleParams <- preProcess(tours.ann[split,], method=c("center", "scale"))
tours.ann <-predict(ScaleParams, tours.ann)

## Dummy Encoding: nominal inputs ##
dummy <- dummyVars( ~ ., data = tours.ann[split, ], fullRank = TRUE)
tours.ann.encode<-as.data.frame(predict(dummy,  tours.ann)) 
tours.ann.encode$Book_12Mo<-tours.ann$Book_12Mo

## Prepare train/validation sets as matrices ##
inp.n <- grep("^(Book_12Mo)", names(tours.ann.encode)) 

x.train <- as.matrix(tours.ann.encode[split,-inp.n])
y.train<- as.matrix(tours.ann.encode[split,"Book_12Mo"])
x.valid<-as.matrix(tours.ann.encode[split.valid,-inp.n])
y.valid<-as.matrix(tours.ann.encode[split.valid,"Book_12Mo"])

# x.test<-as.matrix(tours.ann.encode[split.test,-inp.n])
# ####################
### ANN Building ###
####################
library(keras)

use_session_with_seed(27947, disable_gpu=FALSE)
ann <- keras_model_sequential()
ann %>%
  layer_dense(units = 128, activation = "tanh", input_shape = c(183))%>%   # update input shape
  layer_dense(units = 128, activation = "tanh") %>%
  layer_dense(units = 1, activation = "sigmoid")



ann %>% compile(
  loss = "binary_crossentropy",
  optimizer = "adam",
  metrics = "accuracy"
)



callbacks.list = list(
  callback_early_stopping(
    monitor = "val_loss", # change
    patience = 5
  ),
  callback_model_checkpoint(
    filepath="my_ann_raw.h5",
    monitor = "val_loss",  # change
    save_best_only = TRUE
  )
)



history <- ann %>% fit(
  x= x.train,
  y= y.train,
  epochs = 40,
  validation_data = list(x.valid,y.valid),
  verbose = 1,
  callbacks = callbacks.list
)



ann.select <-load_model_hdf5("my_ann_raw.h5") 


## Prediction ##
ann.prob<-predict_proba(ann.select,x.valid)

# Use alternative cutoff
rocCurve.ann <- roc(tours.ann[split.valid,]$Book_12Mo, ann.prob, quiet=TRUE)
annThresh <-  coords(rocCurve.ann, x = "best", best.method = "closest.topleft", transpose = FALSE)
ann.class <- as.factor(ifelse(ann.prob >= annThresh$threshold, 1,0))
ann.fscore<-confusionMatrix(table(ann.class,tours.ann[split.valid,]$Book_12Mo),
                            positive = "1")$byClass["F1"]

ann.fscore  # f-score=F1 0.51

